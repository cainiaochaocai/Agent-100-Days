# 思考 & 补充学习资料

## 反思问题

- LLM 在回答问题时，它真的“理解”了吗？
- 模型输出的一句话，本质上是什么？
- 为什么模型“会在常识问题上犯低级错误”？

## 补充学习资料

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Transformers, the tech behind LLMs](https://www.youtube.com/watch?v=wjZofJX0v4M)
- [Large Language Moels explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs)
