# 19.结构化输出

## 一、为什么自然语言输出不可控

大模型的默认工作模式是生成“看起来合理的文本”，而不是“满足约束的结果”。这在对话中是优势，在系统中却是灾难。

比如你要 JSON，它偏要回：“好的，这是为您生成的 JSON 数据：...”，还有，偶尔漏掉一个双引号，或者在 Key 值里多加了一个空格，这种不可预测性会导致下游程序崩溃。

自然语言的特点是模糊、冗余、不稳定。这意味着返回结果解析困难，有时候稍微换个说法，或者多一行废话，系统就可能报错。

* 多一行废话，整个系统报错

**示例**

你希望模型返回：

```json
{"score": 0.87, "risk": "high"}
```

但你得到的是：

> “综合来看，该项目风险较高（risk=high），我的评分是 0.87。”

这样的结果后面系统节点就很难处理。所以要想让系统问题就必须让LLM从一个概率性函数接口变成一个稳定、可解析、可约束的函数接口，即要结构化输出。

## 二、常见结构化方式

常见的结构化方式有以下几种：

**JSON（最常用）**

适用于：

* 系统对接
* 数据入库
* 状态传递
* Agent 通信

示例：

```json
{
  "intent": "search",
  "query": "OpenAI agent architecture",
  "confidence": 0.91
}
```

**Markdown（人机混合接口）**

适用于：

* 报告
* 知识库
* 可视化渲染
* 审阅型任务

示例：

```markdown
## 结论
...

## 核心依据
- ...
- ...

## 风险
...
```

**表格 / KV / DSL**

适用于：

* 规则系统
* 流程控制
* 决策配置
* Prompt → 程序桥梁

## 三、结构化输出技巧

结构化输出的核心技巧有以下几种：

**Schema 约束**

在 Prompt 中定义输出结构，限制输出格式。

**示例**

```
你是一个后端服务，不与用户对话。
你只能输出合法 JSON，禁止输出任何解释性文本。

输出必须严格符合以下 JSON Schema：

{
  "type": "object",
  "properties": {
    "intent": {"type": "string"},
    "confidence": {"type": "number", "minimum": 0, "maximum": 1},
    "reason": {"type": "string"}
  },
  "required": ["intent", "confidence", "reason"]
}

如果无法判断，也必须输出符合该 Schema 的 JSON。
```

**负向约束（Negative Prompting）**

很多失败的结构化 Prompt，不是“没说清楚要什么”，而是**没说清楚不能要什么**。常见负向约束：

* 不要解释
* 不要 Markdown
* 不要代码块
* 不要自然语言前后缀
* 不要添加字段

**示例**

```
禁止输出：
- ```json
- 任何自然语言解释
- schema 外的字段
- 注释
- 换行说明

只允许输出：单个、可解析的 JSON 对象。
```

**状态控制**

让模型“在不同阶段干不同的事”，将系统分为收集信息、决策、执行、复核等不同阶段阶段。

**示例**

```json
{
  "state": "need_more_info",
  "missing": ["company_name", "industry"]
}
```

**容错与解析**

即便 Prompt 写得再好，模型偶尔还是会出错（尤其是在处理长文本或小模型时）。这时需要用到工程手段，常用方法如下：

a.json_repair 开源库

这是一个极其强大的 Python 库。当 AI 返回了错误的 JSON（比如少了括号、多了逗号、引号未闭合），`json_repair` 能自动修复这些语法错误，强行将其转换为合规对象。

b.LangChain 结构化输出

LangChain在框架层面支持结构化输出。它主要靠以下两个机制：

* **OutputParsers（输出解析器）：** 自动在 Prompt 末尾注入复杂的 Schema 指令，并在获取输出后尝试解析。如果解析失败，它甚至会**自动重试**（Retry），拿着报错信息回去问 AI：“你写错了，请按这个错误提示修正”。
* **Function Calling（函数调用）：** 现代大模型（如 GPT-4, Claude 3）支持的原生 API。通过在底层协议层面约束输出，效果比单纯靠 Prompt 引导要稳定得多。