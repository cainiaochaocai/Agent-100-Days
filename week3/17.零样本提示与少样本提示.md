# 17.零样本提示与少样本提示

在前两天的课程中，我们学习了 Prompt 的底层逻辑和通用技巧。今天，我们将讨论提示词工程中最具“魔力”的技巧：**如何通过示例让模型学会复杂的模式。**
零样本与少样本，就是两种最基础、也最常被滥用的概率操控技巧。

## 一、 什么是零样本与少样本？

在 AI 的语境下，“Shot” 指的就是**示例（Example）**。

### 1.  零样本(Zero-shot Prompt)

零样本(Zero-shot Prompt)指的是，不给任何示例，只给任务描述，直接让模型完成任务。这完全依赖于模型在预训练阶段习得的通用知识。

**适用场景：** 简单任务、常识性问答、标准格式转换。

**示例**：

```text
请判断下面这段评论的情绪是 正面 / 中性 / 负面：
评论：这个产品还行，但也没什么惊喜。
```

这里没有告诉模型“正面长什么样，负面长什么样”，而是直接依赖模型在预训练中学到的**通用知识**。

 从概率角度看，零样本做了两件事。一是激活一个“任务簇”（情绪判断 / 分类 / 总结 / 翻译）；二是把输出空间粗略收缩到某一类文本分布。所以，零样本适合于那些非常通用的任务场景。

**零样本的局限**

使用零样本时，模型会基于**它的“默认标准”**，风格、边界、分类口径容易漂移，在业务任务中，结果一致性通常不够。一般在探索、验证、Demo阶段用的比较多。

### 2.少样本提示（Few-shot Prompt）

少样本提示（Few-shot Prompt）指的是在执行任务时，先给模型**若干组输入-输出示例**，让它“照着这个模式来”。

**适用场景**: 复杂的逻辑判断、特定风格的模仿、非标准的格式转换、极具挑战的分类任务。
**示例**：

```text
示例 1：
评论：这个产品太好用了，完全超出预期。
情绪：正面

示例 2：
评论：质量一般，没什么亮点。
情绪：中性

示例 3：
评论：非常失望，浪费钱。
情绪：负面

现在请判断：
评论：这个产品还行，但也没什么惊喜。
情绪：
```

这时，模型已经不只是“知道这是个情绪任务”，而是被限制到了一条**更窄的概率轨道**，输出长度、分类标准、决策边界这些都被示例锁定了。

少样本是**激活**模型的**在上下文学习 (In-Context Learning)** 能力，让它在当前的对话窗口内临时“学会”某种特定的规律。

少样本并不是在“教知识”，而是在做这三件事：

1. **定义任务形态**（这是分类，不是点评）
2. **定义输出协议**（只能是 正面 / 中性 / 负面）
3. **塑造判断边界**（什么算中性，什么算负面）

从概率分布上看，是在构造一个**局部的更窄高密度轨道**。

## 二、示例数量为什么“少而精”

很多初学者认为例子越多越好，但事实并非如此。主要原因如下：

1. **Token 成本：** 每一个例子都会消耗 Token，且每个后续回复都要重复计算这些示例。
2. **注意力稀释：** 过多的例子会增加上下文的信噪比，导致模型“抓不住重点”。
3. **边际递减：** 通常情况下，**3-5 个高质量示例**带来的提升最显著，超过 10 个后，性能提升曲线会迅速变平。

简单来说，就是LLM 并不会“归纳总结示例”，它只是会**延续示例所在的局部分布形态**。一旦示例本身不纯，模型就会被你带歪。

**少而精**一般需要遵循以下金律：

1. **挑选高质量示例**
   
   高质量示例要满足以下条件:
* **多样性：** 如果你的分类任务有 A、B、C 三种情况，示例中必须包含这三种情况，不能只给 A。
* **准确性：** 示例的标签必须绝对正确。模型会对示例中的逻辑产生路径依赖。
* **简洁性：** 去除干扰噪声，只保留核心逻辑。
2. **排序**

    大模型存在**近因效应 (Recency Bias)**。模型往往受**最后一个示例**的影响最大，因此将最难、最复杂、或你最希望模型重点模仿的例子放在最后。

3. **动态示例选择** 

    在进阶工程中，不要写死示例。最好建立一个“示例库”，当用户输入 时，通过向量相似度计算，从库里抓取 3 个与  最像的例子塞进 Prompt。这样得到的示例针对性极强，模型几乎不会跑偏。

### 三、何时不该用少样本

尽管少样本很强大，但也要注意使用场景。用错场景，轻则浪费 token，重则直接拉低效果。

#### 1.一句话就能定义清楚的简单任务，不值得用少样本

如果你的需求用**一条清晰指令**就能约束模型行为，那么再补示例，通常不会带来显著收益，反而增加成本与噪音。

比如在以下提示词中

> 把下面文本改写为更正式的书面语。

再加一堆示例：

> 示例：
> 输入：这个功能有点问题
> 输出：该功能目前存在一定缺陷
> …

这种情况下，模型本身已经掌握“口语 → 书面语”的映射，示例并不会显著提高稳定性。

这类场景下更优做法是**零样本 + 约束**。

> 将下面文本改写为正式书面语，保持原意，不添加新信息。

这样的提示词更短、更便宜、可控性更强。

#### 2.高度发散型任务，少样本往往会压缩创造空间

在创作、头脑风暴、概念探索类任务中，少样本反而会让输出风格高度趋同于示例，而不是帮你探索新空间。

**典型反例**

> 写 5 个创业点子。
> 示例：
> 
> 1. AI 写作助手
> 2. AI 投资分析工具
> 3. AI 简历优化平台

结果大概率会变成：

* AI 教学助手
* AI 医疗问诊
* AI 客服系统

看似在“生成新想法”，实际上已经失去了泛化处理能力。

这类场景更优做法是用**约束维度**代替少样本

> 写 5 个创业点子，要求：
> 
> * 尽量跨领域
> * 避免常见 AI 应用方向
> * 每个点子说明其反直觉之处

这样模型更容易打开解空间。

#### 3.长链路复杂任务中，少样本容易诱发“隐性过拟合”

在包含**多步骤推理 / 多轮决策 / 长输出结构**的任务中， 少样本有时会导致模型模仿“表面格式”、复制“局部策略”、错配“隐藏目标”。

**典型反例**

> 请分析一家公司的投资价值。
> 示例：
> 先宏观 → 再行业 → 再财务 → 给结论

这样模型容易变成“填模板机器”，即便公司类型完全不适配，也会强行往示例结构里塞。表面看更专业，实则**思考退化为套壳**。

复杂任务的更优做法用**角色 + 目标 + 评价标准 + 过程约束**替代示例：

> 你是专业投资分析师，目标是判断该公司是否具备长期配置价值。
> 请基于你认为最关键的分析维度展开，不限结构，但需明确：
> 
> * 核心风险
> * 核心增长驱动
> * 关键不确定性

总的来说，少样本适合用在目标输出分布清晰、难以用语言精确定义，并且希望模型**稳定模仿某类模式**的场景。而不适合用在规则极其简单的任务、探索、创意、开放解空间的任务、复杂系统级推理任务。
