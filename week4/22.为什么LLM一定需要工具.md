# 22. 为什么 LLM 一定需要工具

从“会说话的模型”，走向“会使用工具的智能”

## 一、LLM 的三大天然缺陷

过去两年，大模型参数量和推理能力不断增加，但在真实业务场景中，我们很快会撞上三堵“结构性天花板”。

### 1.LLM 天然无法“行动”

LLM 的核心能力仅是根据上下文预测下一个 token。

它**无法真正执行动作**，比如查数据库、调用系统接口、运行代码等，无法改变真是世界状态

**示例**：

> 你让 LLM 创建一个订单，它只能生成订单文本描述，而不会真的在系统中创建订单。

### 2.LLM 天然不可信（不可验证）

LLM 输出的是**语言概率**，不是**事实**。

真实系统要求：

* 可查询
* 可校验
* 可追溯
* 可回滚

**示例**：

> 模型可能生成一个看似合理的股票收益预测，但实际数据库中该股票数据并不存在。
> 只有通过工具查询真实数据，才能保证结果可靠。

### 3.LLM 天然不具备“持续能力”

模型没有长期状态或权限，每一次对话都是一次短暂扮演，无法沉淀为长期可复用能力。

**示例**：

> 让模型扮演财务助手，它可以回答问题，但不会记录上次处理过的账单，也无法自动累积数据。

所以，如果LLM只是不断堆叠参数（更大的“大脑”），它依然无法跨越现实世界的鸿沟。要想使LLM在真实业务场景中落地，就要让它学会像人一样，精准地使用工具。

## 二、工具在系统中的角色

要想了解工具在系统中的角色，可以看看人类是怎么做的。真正强大的人，不是记住所有知识的人，而是**知道什么时候该用什么工具的人**。

比如，工程师不会心算百万次乘法，而是使用计算器；物理学家不会在脑中模拟量子系统，而是建立数学模型；金融分析师不会凭感觉给结论，而是写公式、跑模型、查数据。

LLM 目前擅长“模仿语言”，却不擅长“真正使用工具”，比如数学。

**示例**：

```text
LLM可以写出公式：E = mc²
但是面对一个量子能级跃迁问题，它无法建立变量、构建模型、推导结果并验证。
```

因为LLM 本质是语言的概率压缩器，而数学、物理等，是高度抽象的符号系统。

它们之间存在一条鸿沟。而这条鸿沟，不是“参数量”能填平的，而是工具使用能力。

从系统结构上看工具不是“给模型接 API”，是智能体的执行层与能力模块。更准确的说，工具是智能体的**确定性**能力模块。
工具负责：

* 执行动作（查库 / 下单 / 搜索 / 写文件）
* 访问真实世界
* 提供可验证结果
* 承担风险边界

而 LLM 负责：

* 理解
* 决策
* 规划
* 调度

**示例**：

* 用户想查询明天的天气
* LLM 决定使用 `get_weather_api` 工具
* 工具返回实际天气数据
* LLM 基于结果生成周报

## 三、工具 / 技能 / 智能体 的层级关系

理解三者区别，有助于设计清晰的智能体架构。

| 层级              | 核心定义                        | 类比    | 示例                          |
| --------------- | --------------------------- | ----- | --------------------------- |
| **工具 (Tool)**   | 单一功能的 API 或函数，只执行，不决策       | 锤子、电钻 | `get_weather_api`：返回实时天气    |
| **技能 (Skill)**  | 特定任务的**工具组合 + 流程逻辑**，可复用    | 木工手艺  | “生成天气周报并翻译成英文”              |
| **智能体 (Agent)** | 核心大脑，**自主规划 + 调度技能 + 异常处理** | 装修队长  | “根据明天天气和客流量，自动调整店铺空调温度和备货量” |

**示例场景**：

* **工具**：调用翻译接口
* **技能**：自动把天气数据抓取、生成报告并翻译
* **智能体**：根据商店位置和天气自动调整库存和空调策略
