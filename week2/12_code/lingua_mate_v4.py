import gradio as gr
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai.chat_models import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
import os
import time
import whisper
import edge_tts
from dotenv import load_dotenv

load_dotenv()

assert os.getenv("OPENAI_API_KEY"), "è¯·å…ˆé…ç½® OPENAI_API_KEY"

asr_model = whisper.load_model("turbo")


# å­˜å‚¨ä¸åŒç”¨æˆ·çš„è®°å¿†
store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


english_tutor_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a friendly English tutor.

        Help the learner improve step by step.
        Keep responses short, clear, and conversational.

        When correcting:
        - First show the corrected sentence.
        - Then give a very brief reason (1â€“2 short sentences).
        - Use simple, everyday English.
        - Encourage the learner to try again.

        Do not give long explanations or grammar lectures.
    """),
    MessagesPlaceholder(variable_name="chat_history"), # è®°å¿†å­˜æ”¾å¤„
    ("user", "{user_message}"),
])

model = ChatOpenAI(model="qwen-flash", base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
output_parser = StrOutputParser()

# ä½¿ç”¨ LCEL è¡¨è¾¾å¼å°† promptã€modelã€parser ä¸²è”èµ·æ¥
chain = english_tutor_prompt | model | output_parser

chain_with_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="user_message",
    history_messages_key="chat_history",
)


def speech_to_text(audio_path: str) -> str:
    """
    æŠŠç”¨æˆ·è¯­éŸ³è½¬æˆæ–‡æœ¬
    """
    transcribed = asr_model.transcribe(audio_path)
    return transcribed["text"]

def text_to_speech(text: str) -> str:
    """
    è¾“å…¥æ–‡æœ¬ â†’ è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    print(f"[TTS] Processing: {text}")
    audio_path = f"./output_{int(time.time())}.mp3"
    communicate = edge_tts.Communicate(text, "en-GB-SoniaNeural")
    with open(audio_path, "wb") as file:
        for chunk in communicate.stream_sync():
            if chunk["type"] == "audio":
                file.write(chunk["data"])
    return audio_path


def stream_ai_response(user_message: str, session_id: str):
    """
    è°ƒç”¨å¤§æ¨¡å‹ï¼Œç”Ÿæˆå›å¤å†…å®¹
    - user_message: å½“å‰ç”¨æˆ·è¾“å…¥
    - session_id: ä¼šè¯IDï¼ˆç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·ï¼‰
    """
   
    partial_answer = ""

    for chunk in chain_with_history.stream(
        {"user_message": user_message},
        config={"configurable": {"session_id": session_id}}
    ):
        if chunk:
            partial_answer += chunk
            yield partial_answer

def process_voice_and_stream(audio_path: str, history: list):
    """
    Gradio ChatInterface çš„å›è°ƒå‡½æ•°
    è´Ÿè´£ï¼š
    1. æ¥æ”¶ç”¨æˆ·è¾“å…¥
    2. è°ƒç”¨ LLM ç”Ÿæˆå›å¤
    3. è¿”å›ç»™å‰ç«¯å±•ç¤º
    """
    user_text = speech_to_text(audio_path)
    if not user_text:
        yield history, None
        return
    
    history.append({"role": "user", "content": user_text})
    history.append({"role": "assistant", "content": ""})
    yield history, None

    session_id = "user_001"  # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”æ ¹æ®ç”¨æˆ·èº«ä»½åŠ¨æ€ç”Ÿæˆ

    full_response = ""
    for partial in stream_ai_response(user_text, session_id):
        full_response = partial
        history[-1]["content"] = full_response
        # å®æ—¶é€å—æ¨é€æ–‡æœ¬åˆ° Chatbot
        yield history, None

    audio_reply = text_to_speech(full_response)
    yield history, audio_reply

with gr.Blocks(theme=gr.themes.Soft()) as chat_ui:
    gr.Markdown("# ğŸ™ï¸ æµå¼å¤šæ¨¡æ€è‹±è¯­åŠ©æ‰‹")
    
    with gr.Row():
        with gr.Column(scale=1):
            audio_input = gr.Audio(
                sources=["microphone"],
                type="filepath",
                label="è¯·å¼€å£è¯´è‹±è¯­ (Speak English)"
            )
            audio_output = gr.Audio(label="AI è¯­éŸ³å›å¤", autoplay=True)
            
        with gr.Column(scale=2):
            # ä½¿ç”¨ type="messages" é€‚é…æœ€æ–°çš„ LangChain/Gradio æ ¼å¼
            chatbot = gr.Chatbot(label="å¯¹è¯è®°å½•")
            clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")

    # äº¤äº’ç»‘å®š
    # å½“éŸ³é¢‘æ”¹å˜æ—¶è§¦å‘
    audio_input.stop_recording(
        fn=process_voice_and_stream,
        inputs=[audio_input, chatbot],
        outputs=[chatbot, audio_output]
    )
    
    clear_btn.click(lambda: [], None, chatbot)


if __name__ == "__main__":
    chat_ui.launch(share=True)  # share=True ä¼šç”Ÿæˆå…¬ç½‘è®¿é—®é“¾æ¥